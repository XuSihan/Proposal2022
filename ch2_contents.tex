\subsection{研究内容}\label{ch2content}

本项目面向医疗卫生行业的数据分析需求，针对电子医疗记录分析存在的研究队列识别困
难、记录时间不规则、模型解释匮乏等问题，以深度学习为基础手段，研究电子医疗记录分
析建模的理论和方法，力争构建端到端的电子医疗记录分析方案，突破队列识别、EMR插补
和可解释性分析模型等关键技术，并在基于电子医疗记录的临床任务上验证本项目的研究成
果。

项目研究工作从队列识别、EMR插补、可解释分析模型和临床任务验证四个层次展开，本项
目的挑战、科学问题和研究内容关系如图~\ref{fig:ch2:rc}所示。各部分研究内容具体介
绍如下：

\begin{figure}[htp]
    \begin{small}
        \begin{center}
            \includegraphics[width=0.95\textwidth]{ch2_framework.pdf}
        \end{center}
        \caption{挑战、科学问题和研究内容关系图}
        \label{fig:ch2:rc}
    \end{small}
\end{figure}

\subsubsection{基于决策行为模拟的黑盒测试}

借鉴传统软件的路径覆盖测试方法，许多研究提出针对深度学习模型的覆盖性测试方法（参
见\ref{relatedwork} 国内外研究现状及发展动态分析），这些测试覆盖指标和方法主要是
针对白盒的场景，即测试者掌握所有的训练数据和整个深度学习模型，\textbf{但在许多场
景中，测试者无法访问训练数据和模型内部结构，但仍需要对模型的泛化能力进行测试，即
黑盒测试，如深度学习模型是某个公司私有的或者由第三方机构提供，他们只提供了接口或
者打包的可执行程序。}因此，本项目面向黑盒测试场景，研究基于决策行为模拟的黑盒测
试方法。

以分类模型为例，给定一个黑盒深度学习模型$\mathcal M$和测试数据集$\mathcal
D_{\text{test}}=\{x^{(i)},y^{(i)}\}$，测试者可以得到模型针对每个输入
$x^{(i)}$（input）的输出$\hat{y}^{(i)}$，通常是该输入属于各个类别的概率分布，除
此之外，测试者无法知道该模型的训练数据和内部结构。可见，深度学习模型黑盒测试面临
两个主要问题：
\begin{itemize}
    \item \textbf{如何建立模型有关的测试方法？}仅有的几个黑盒模型测试方法仅针对
    数据的多样性进行评估，无法准确反映模型的性能，也不能给模型改进提供有效建议。
    \item \textbf{如何掌握模型的决策机制？}黑盒测试中，测试者无法了解模型的结
    构，模型对测试用例的决策过程无法知晓。
\end{itemize}

\begin{figure}[htp]
    \begin{small}
        \begin{center}
            \includegraphics[width=0.75\textwidth]{ch2_2Btest.pdf}
        \end{center}
        \caption{基于决策行为模拟的黑盒测试研究内容}
        \label{fig:ch2:2Btest}
    \end{small}
\end{figure}
本项目深度学习模型黑盒测试的主要研究内容如\cref{fig:ch2:2Btest}所示，\textbf{本项目首先
研究针对黑盒模型的预测行为模拟方法，拟利用知识萃取的方法，通过建立副本模型
$\mathcal M^\prime$（如决策树）萃取黑盒模型$\mathcal M$的知识，模拟$\mathcal M$
的预测行为；然后，在副本模型的基础上，本项目拟建立基于决策路径覆盖度的测试方法，
通过覆盖度指标反映模型的决策机制和泛化能力。}

\subsubsection{基于层次语义理解的白盒测试}

除了黑盒测试的场景，白盒测试的需求也非常多，如企业自己开发的深度学习模型，在白盒
测试中，测试者可以访问模型的内部结构$\mathcal M(\bm W, \bm b)$和训练数据集
$\mathcal D_{train}=\{(x^{(i)}, y^{(i)}\})$。目前，针对深度学习模型的白盒测试方
法可扩展性和可解释性较差，无法应用于大规模深度学习模型，如
BERT~\cite{kenton2019bert}，MAE~\cite{he2021masked}等，而且测试结果无法给模型训
练提供有效反馈，辅助模型优化。因此，\textbf{本项目提出针对白盒深度学习模型的层次
语义理解方法，并利用各层的决策语义训练一个副本模型中，保证副本模型的决策路径与原
白盒模型一致；然后围绕副本模型进行决策路径覆盖度测试，决策路径具有较强的可解释
性，可引导测试数据生成和模型优化。}

\begin{figure}[htp]
    \begin{small}
        \begin{center}
            \includegraphics[width=0.9\textwidth]{ch2_WBtest.pdf}
        \end{center}
        \caption{基于层次语义理解的白盒测试研究内容}
        \label{fig:ch2:WBtest}
    \end{small}
\end{figure}

本项目基于层次语义理解的白盒测试研究内容如\cref{fig:ch2:WBtest}所示，在白盒测试
的场景下，本项目首先研究如何从深度学习模型中抽取出各层（layer）的决策语义信息，
研究表明，深度学习模型对输入的决策是由粗粒度到细粒度的。\cref{fig:ch2:WBtest}举
例说明了从3组神经网络层的输出抽取各组网络的预测行为，例如：输入一个猫的图片，第1
组神经网络判断该图片是否是动物，接着，第2组神经网络判断该图片是否是猫科动物，最
后，第3组神经网络将该图片分类为猫。\textbf{本项目拟研究如何实现层次语义理解，自
动地从深度学习模型中抽取出各层的决策语义}。

在层次语义理解的基础上，\textbf{本项目拟融合白盒模型的多层次决策语义训练一个副本
模型，使该副本模型的决策路径与原白盒模型一致，且具有良好的可解释性}。此外，知识
蒸馏得到的模型通常规模较小，和直接测试原白盒模型相比，测试副本模型可有效提高测试
效率。\textbf{在得到可解释的副本模型后，本项目拟研究并提出针对该可解释模型的决策
路径覆盖度，用于分析测试样本的多样性和充分性}。

\subsubsection{融合反馈偏置的自适应测试集生成}
深度学习模型的测试依赖于有标签的测试集，以判断模型预测结果是否符合预期，然而，测
试集的标注成本通常较高。一方面，深度学习模型的测试输入标注通常依赖于人工经验，一
个测试数据需要多个经验丰富的标注人员来标出，以保证标注正确性；另一方面，为了测试
充分性和准确评估模型性能，测试集的规模通常较大，尽可能代表真实的测试数据分布，导
致标注成本较高。因此，{需要合理平衡测试集的规模和质量，在有限标注成本空间内选取
对样本空间具有高代表性的测试数据，生成规模相对较小的高质量测试集优先标注}。\textbf{本项
目拟提出一种可解释的自适应测试集生成方法，给定输入空间内大规模无标注测试数据，针
对充分性测试和模型性能评估两个测试目标，结合测试执行反馈，筛选出具有不同检测能力
的测试数据，生成指定规模的高质量测试集。}

\begin{figure}[htp]
    \begin{small}
        \begin{center}
            \includegraphics[width=0.95\textwidth]{ch2_TestSelection.pdf}
        \end{center}
        \caption{可解释预测模型研究内容}
        \label{fig:ch2:testselection}
    \end{small}
\end{figure}

如\cref{fig:ch2:testselection}所示，本项目拟在自适应测试中考虑可解释性，现有工作
缺乏对测试数据生成和测试结果反馈的可解释性，导致针对深度学习的有效测试信息较少，
难以辅助修复模型缺陷。结合前面研究内容，本项目可从黑盒和白盒两个角度将复杂神经网
络抽象为可解释蒸馏模型，对每个输入数据都输出具有可解释性的决策路径。针对给定大规
模无标注测试数据，可经过可解释蒸馏模型得到所有测试数据的决策路径分布，具有相同决
策路径的测试数据为一组。根据每组测试数据规模大小，采用聚类分析将具有相同决策路径
的测试数据分为多个类簇，利用基于最大平均差异法为从每簇测试数据中选取固定总数的测
试数据作为代表性数据，得到与无标注数据集有近似决策路径分布的初始子集。\textbf{本
项目拟从充分性测试和准确评估模型两个测试目标来制定自适应反馈机制，将复杂神经网络
抽象成可解释蒸馏模型，选取与大规模无标注测试数据具有近似决策路径分布的代表性数据
进行标注，为测试人员提供全阶段的可解释测试方法}。


\subsection{研究目标}\label{ch2target}

本项目从深度学习模型部署的实际需求和人工智能软件安全性的前沿问题出发，针对深度学
习模型测试方法伸缩性差、缺乏可解释性和测试数据标注成本高等问题，分别建立基于决策
路径的黑盒测试和白盒测试方法，在此基础上构建融合反馈偏置的自适应测试集生成方法，
形成一套从测试指标、测试用例生成到测试反馈的深度学习可解释测试解决方案，并在自动
驾驶、人脸识别等实际应用中检验研究成果的效果。

具体研究目标包括：

\textbf{在技术方面}，本项目拟在以下三方面实现技术突破： (a) 提出基于决策行为模拟
的黑盒测试方法，利用知识蒸馏技术，训练副本模型，模拟黑盒模型的预测行为，实现伸缩
性强、可解释性的黑盒测试；(b) 提出基于层次语义理解理解的白盒测试方法，抽取模型的
中间表示和决策路径，训练副本模型，实现伸缩性强、可解释的白盒测试；(c) 提出融合反
馈偏置的自适应测试集生成方法，针对测试目标，结合测试执行反馈，选取与大规模无标注
测试数据具有近似决策路径分布的代表性数据。

\textbf{在成果形式方面}，本项目力争在CCF-A类推荐期刊/会议或其他SCI期刊上发表高水
平论文3-6篇；申请专利2项；并开源相关研究工作，供用户下载，并提供说明和使用文档。

\textbf{在人才培养方面}，通过本项目研究，培养深度学习测试、人工智能安全等前沿领
域的青年人才，拟培养研究生2-3人。

\subsection{拟解决的关键科学问题}

基于上述研究目标和研究内容，本项目拟在以下几个关键理论和技术问题上有所突破：

\subsubsection{在黑盒场景下，仅根据模型输入输出，模拟构建黑盒模型的决策路径}

在黑盒测试中，测试者无法了解待测模型的内部结构和训练数据集，仅能得到测试输入输
出，因此无法知晓模型对输入样本是如何决策判断的。现有测试覆盖指标主要基于神经网络
结构的覆盖，仅有黑盒测试研究局限于与模型无关的测试数据多样性的评估，尚未建立模型
有关的黑盒测试方法，无法提供针对特定模型的测试逻辑。因此，在黑盒测试中，如何通过
输入输出模拟模型的决策路径，建立基于决策路径的测试覆盖度指标，以实现可解释黑盒测
试是本项目拟解决的一个关键科学问题。


\subsubsection{在白盒场景下，分层抽象模型内在决策路径，建立基于决策路径的测试覆盖指标}

在白盒测试中，测试者可以得到模型的内部结构和训练数据集，但是深度学习模型的可解释
性差，难以知晓模型对于特定样本是如何决策判断的。另一方面，现有深度学习测试的研究
主要围绕神经元取值和覆盖度进行分析，不仅计算复杂度高，难以应用于大模型，而且缺乏
语义可解释性，相应的测试报告无法给模型开发人员提供有效指导。因此，在白盒测试中，
如何分层抽象深度学习模型内在的决策路径，以实现基于决策路径的可解释测试是本项目拟
解决的另一个关键科学问题。

\subsubsection{在决策路径覆盖引导下，融合反馈偏置筛选规模可控的测试数据评估模型性能}

深度学习模型测试依赖于数据标注，实际应用中，需要合理平衡测试集的规模和质量，在有
限标注成本空间内选取对样本空间最具代表性的测试数据。在本项目黑盒和白盒决策路径覆
盖测试的基础上，已选择的测试数据执行结果可为后续测试数据选择提供模型正确性反馈和
路径覆盖反馈，指导后续测试数据筛选方式，因此，如何对这种反馈偏置进行形式化建模，
将其用于代表性测试用例的持续筛选中，并适应不同的测试目标，也是本项目拟解决的关键
科学问题问题之一。