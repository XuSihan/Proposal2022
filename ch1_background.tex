% !TEX root=./proposal.tex

\subsection{研究背景和科学意义}


%0.人工智能技术很广泛，智能软件越来越多进入人们的生活1.于此同时，其安全问题也得
%到越来越多的关注2.当前的研究主要针对单个智能组件研究其脆弱性，如对抗攻击，后门
%攻击等。近年来，逐渐有少量研究深度学习基础包和依赖库的漏洞，然而如何利用第三方
%开源组件漏洞去激活智能组件的脆弱性研究较少。
%举例
%挑战：3点
%本项目的研究意义3点

%
% 0.人工智能技术很广泛，智能软件越来越多进入人们的生活
近年来，在数据和算力的驱动下，深度学习取得了巨大的成功。如\cref{fig:ch1:intro}所
示，深度学习通过特征变换和逐层处理，学习输入数据的特征表示，深度学习模型对复杂
问题的解决能力使其研究成果逐渐从实验室走向实际应用，如计算机视觉、语音识别和机器
翻译等，并开始部署在自动驾驶、智慧医疗和航天等关键任务上。在获得巨大成功的同时，
深度学习的错误行为也导致了很多安全事故。2018年3月19日，在美国亚利桑那州，一辆处
在自动驾驶状态的Uber撞击一名女子，致其不幸身亡，同年7月，Uber宣布停止研发自动驾
驶货车。由于深度学习越来越多地被部署在自动驾驶、恶意软件检测以及飞机碰撞避免等安
全攸关系统，因此\textbf{迫切需要在部署深度学习模型前找到其潜在的错误行为来提升深
度学习在安全攸关任务上的可靠性}。

Szegedy等人首次发现，数据中微小的扰动，即便无法被人类发现，却可能造成模型做出错
误判断~\cite{szegedy2013intriguing}，并由此引发了很多关于对抗鲁棒性的研究。事实
上，部署在真实世界的模型也可能遇到各种各样的自然意外，如天气的改变、路标损坏等，
这些自然对抗样本也可能导致模型做出错误预测。除了鲁棒性，\textbf{模型的泛化能力对
于其走向实际应用也有极为重要的意义}。深度学习的目标可定义为训练一个模型${f}$，使
得该模型能够适用于真实数据分布$D_{gt}$中任意一个从未见过的数据，而不仅仅是记住训
练数据。为了提高真实部署的可靠性，需要系统测试深度学习模型的泛化能力
$\gamma_{gt}$：$\mathbb{E}_{(x, y) \sim \mathcal{D}_{g t}} \mathbb{I}[f(x)=y]$。
然而，由于客观世界的真实数据分布是未知的，因此通常在测试集$D_{\text{test}}$上评
估模型性能$\gamma_{\text {test }}:\left(1 /\left|D_{\text {test }}\right|\right)
\sum_{(x, y) \in D_{\text {test }}} \mathbb{I}[f(x)=y]$。若${f}$的泛化能力较强，
则其在足够充分的测试集$D_{\text{test}}$上的性能应接近其在真实数据分布$D_{gt}$上
的性能。因此，针对泛化能力的深度学习模型\textbf{测试目标}为：
\begin{itemize}
    \item 找到测试数据$(x, y)$使得模型做出错误预测，即$(x, y) \in D \cdot f(x)
    \neq y$;
    \item 生成测试数据集$\mathcal{D}_{\text{test}} \sim \mathcal{D}_{\text{gt}}$
    ，以揭示模型在真实数据分布上所期望的性能$\gamma_{gt}$和实际测试集上所表现的
    性能$\gamma_{\text{test}}$之间的差异；
    \item 根据测试反馈信息，找到模型在泛化能力上的不足，进一步提升模型性能。
\end{itemize}


%美国白宫颁布了《维护美国在人工智能领域领导地位》、《国家人工智能研发战略》；欧
%盟致力于打造“从实验室进入市场”，发布《2021人工智能协调计划审查》；俄罗斯发布
%《2030年前国家人工智能发展战略》； 2017年7月，我国国务院印发《新一代人工智能发
%展规划》，旨在构筑我国人工智能发展的先发优势，2019年科技部印发《国家新一代人工
%智能创新发展试验区建设工作指引》，全面提升人工智能创新能力和水平。
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.7\linewidth]{intro.pdf}
    \caption{深度神经网络测试示意}
    \label{fig:ch1:intro}
\end{figure}


%2019年国家新一代人工智能治理专业委员会发布《新一代人工智能治理原则——发展负责任
%的人工智能》，该文件中指出“\textbf{人工智能系统应不断提升透明性、可解释性、可靠
%性、可控性}，逐步实现可审核、可监督、可追溯、可信赖”。

% 2. 现有工作和方法的不足
目前国内外有许多关于人工智能安全性的研究，包括对抗攻击
~\cite{szegedy2013intriguing}、中毒攻击~\cite{zhao2020shielding}、后门攻击
~\cite{ge2021anti}等。在智能软件测试方面，加拿大阿尔伯塔大学的Lei Ma团队深入研究
了深度学习覆盖性指标~\cite{ma2018deepgauge,ma2019deepct}、测试数据生成
~\cite{xie2019coverage,xie2019deephunter}、鲁棒性
~\cite{wang2020deepsonar,sun2020stealthy,zhang2020generating}和模型修复
~\cite{yu2021deeprepair}等方面。国内南京大学的陈振宇老师团队在对话系统
~\cite{liu2021dialtest}、医疗~\cite{hou2021taumed}、机器翻译
~\cite{ji2021automated}、司法文书~\cite{guo2020taujud}、深度学习框架测试
~\cite{zhang2021duo,zhang2021predoo,luo2021graph}等领域展开关于智能软件测试方法
的深入研究。\textbf{本项目申请人也在自动驾驶软件安全方面提出了针对神经网络模型的
确定性测试数据集生成方法~\cite{xu2021deepsuite}}。然而，智能软件大量依赖基础库和
第三方依赖库，其脆弱性来源包括智能组件脆弱性、非智能组件脆弱性以及跨组件脆弱
性。\textbf{现有工作主要集中于单个组件的脆弱性，而对组件间的交互影响研究较少，尤
其缺乏第三方组件漏洞对智能组件影响的研究}。例如，利用OpenCV的一个堆缓冲区溢出漏
洞（CVE-2018-5268）可以给微软的深度学习开发框架Cognitive Toolkit引入一个任意写漏
洞，通过一个恶意构造的图片输入，导致深度学习模型对其它图片输入都做出错误预
测。\textbf{可见，第三方组件中存在的漏洞也可能作为智能组件脆弱点的突破口，从而威
胁整个智能软件的安全性}。


% 3. 现有不足

主要存在以下问题：

\textbf{（1）测试指标伸缩性差，难以适用于大规模深度学习模型}

随着数据和算力的发展，深度学习模型的规模近年来呈越来越大的趋势，很多研究证明了大
规模模型对复杂问题的解决能力。然而，现有的深度学习结构覆盖测试指标大多难以适用于
大规模深度学习模型，主要体现在以下两个方面：第一，随着模型复杂度的提高，神经元和
其取值组合的数量也随之提高，以神经元为基础结构的结构覆盖率和测试多样性之间的相关
性越来越小，导致结构覆盖率对测试集质量的评估能力骤减；第二，现有结构覆盖指标的计
算复杂度与神经元的个数或训练集的规模呈线性增长关系，因次伸缩性较差，难以适用于部
署于真实世界的大规模深度学习模型。


\textbf{（2）测试结果缺乏可解释性，难以辅助开发人员修复模型}

面向深度学习模型的系统性测试，不仅要评估深度学习模型在特定测试集上的性能表现，还
需要建立测试结果与模型行为的联系，从而辅助开发人员修复提升模型。由于深度学习模型
的黑盒性质，现有的基于神经元的结构覆盖指标不能体现深度学习系统的决策逻辑，缺乏有
效语义。虽然在测试覆盖指标的引导下可以生成测试数据，暴露模型的错误行为，但与传统
软件不同的是，开发人员无法知道这些测试数据的成功或失效执行的根本原因，缺乏可解释
性的测试结果很难辅助开发人员定位模型缺陷，提升模型性能。

\textbf{（3）测试数据的标注成本过高，对测试用例集效率控制不足}

测试用例由输入数据和预期输出两部分组成。在测试一个深度学习模型时，其输入数据的样
本空间经常较大，而人工标注预期输出的成本较高，因此很难在系统部署前检测每个潜在数
据样本的预测正确性。比如图片分类任务中，输入数据是高维连续的图像数据，目前对图像
的自动标注研究尚在起步阶段，通常需要人工标注图片的类别作为测试用例的预期输出，在
执行测试用例后，根据模型的输出是否符合预期来判断测试用例的成功与否。与此同时，如
上文所述，有效评估深度学习模型的泛化能力对测试数据集的质量有较高要求，即期望测试
数据集能够尽可能模拟深度学习模型的每个状态，从而避免在系统部署后仍然存在大量意外
输入，导致模型决策错误。为了在有限成本空间内准确评估模型，需要提高测试用例集的效
率，生成规模小、检测能力强的测试用例集。


% 4. 研究方法
本项目直接面向国家人工智能安全可靠发展的重大需求，结合智能软件的特性，从智能组件
确定性、第三方组件脆弱性和跨组件漏洞三个角度研究智能软件的脆弱性，解决了智能软件
不确定性、复杂性和漏洞高隐蔽性带来的挑战，提升智能软件的安全性和可靠性，为智能软
件部署在安全攸关领域提供核心技术支撑。本项目的研究意义主要体现在以下四个方面：

\begin{itemize}
    \item[(1)]\textbf{本项目拟结合神经网络覆盖性测试指标和因果分析，实现具有可解
    释性的智能组件覆盖性测试}。智能组件作为智能软件的核心组成部分，其预测结果影
    响智能软件的正确性。在真正部署智能软件之前，对智能组件进行充分性覆盖测试具有
    重要意义。现有覆盖性测试指标缺乏可解释性，只反映了对特定覆盖条件的满足程度，
    无法定位失效原因。本项目拟结合因果分析和覆盖测试，能够有效分析神经元、参数和
    激活层对测试结果的影响，定位智能组件失效原因，帮助修复智能组件。
    \item[(2)]\textbf{本项目拟构建第三方组件漏洞知识库，以智能组件为输入挖掘非智
    能组件漏洞，实现非智能组件脆弱性测试方法}。涵盖基础框架组件在内的第三方组件
    漏洞，也是造成智能软件脆弱性的重要原因。本项目拟构建面向智能软件的第三方组件
    漏洞知识库，快速有效地发现智能软件里包含的已知组件漏洞；另一方面，为了挖掘智
    能软件中的未知组件漏洞，以智能组件为输入对非智能组件进行模糊测试，发现缓冲区
    溢出、XXX等可能带来安全风险的组件漏洞。
    \item[(3)]\textbf{本项目拟结合单组件脆弱性分析结果和多组件依赖关系，挖掘跨组
    件脆弱通路，实现智能软件跨组件脆弱性分析的通用模型}。智能软件跨组件漏洞具有
    高隐蔽性。第三方组件漏洞给智能软件带来的脆弱点与传统软件不同，利用第三方组件
    漏洞攻击智能软件不易被发现。一方面，利用第三方组件漏洞可以攻击人工智能基础框
    架中存在的漏洞，导致智能组件做出错误预测；另一方面，第三方组件漏洞也可以直接
    攻击智能组件，导致智能软件出现中毒攻击、模型萃取、隐私泄露等安全威胁。
    \item[(4)]\textbf{本项目拟在基于人工智能的自动驾驶软件上验证上述方案的可行
    性，助力自动驾驶软件安全可靠落地}。近年来，关于自动驾驶软件的安全性和可靠性
    的关注显著增加。截至XXX年。。。本项目拟与XXX和XXX合作，在自动驾驶软件上挖掘
    智能组件、非智能组件以及跨组件的脆弱性，辅助提高自动驾驶软件的安全性和可靠性。
\end{itemize}

% 5. 研究意义

\input{relatedwork.tex}