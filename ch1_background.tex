% !TEX root=./proposal.tex

\subsection{研究背景和科学意义}


%0.人工智能技术很广泛，智能软件越来越多进入人们的生活1.于此同时，其安全问题也得
%到越来越多的关注2.当前的研究主要针对单个智能组件研究其脆弱性，如对抗攻击，后门
%攻击等。近年来，逐渐有少量研究深度学习基础包和依赖库的漏洞，然而如何利用第三方
%开源组件漏洞去激活智能组件的脆弱性研究较少。
%举例
%挑战：3点
%本项目的研究意义3点

%
% 0.人工智能技术很广泛，智能软件越来越多进入人们的生活
近年来，在数据和算力的驱动下，深度学习取得了巨大的成功。如\cref{fig:ch1:intro}所
示，深度学习通过特征变换和逐层处理，学习输入数据的特征表示，深度学习模型对复杂问
题的解决能力使其研究成果逐渐从实验室走向实际应用，如计算机视觉、语音识别和机器翻
译等，并开始部署在自动驾驶、智慧医疗和航天等关键任务上。在获得巨大成功的同时，深
度学习的错误行为也导致了很多安全事故。2018年3月19日，在美国亚利桑那州，一辆处在
自动驾驶状态的Uber撞击一名女子，致其不幸身亡，同年7月，Uber宣布停止研发自动驾驶
货车。这些事故发生的根本原因是现有技术对深度学习模型的可靠性缺乏系统性测试评估，
这不仅为应用本身埋下了隐患，也阻碍了深度学习技术在安全攸关任务（如交通、医疗、军
工）的应用。因此，\textbf{迫切需要在部署深度学习模型前找到其潜在的错误行为来提升
深度学习在安全攸关任务上的可靠性}。

Szegedy等人首次发现，数据中微小的扰动，即便无法被人类发现，却可能造成模型做出错
误判断~\cite{szegedy2013intriguing}，并由此引发了很多关于对抗鲁棒性的研究。事实
上，部署在真实世界的模型也可能遇到各种各样的自然意外，如天气的改变、路标损坏等，
这些自然对抗样本也可能导致模型做出错误预测。除了鲁棒性，\textbf{模型的泛化能力对
于其走向实际应用也有极为重要的意义}。深度学习的目标可定义为训练一个模型${f}$，使
得该模型能够适用于真实数据分布$D_{gt}$中任意一个从未见过的数据，而不仅仅是记住训
练数据。为了提高真实部署的可靠性，需要系统测试深度学习模型的泛化能力
$\gamma_{gt}$：$\mathbb{E}_{(x, y) \sim \mathcal{D}_{g t}} \mathbb{I}[f(x)=y]$。
然而，由于客观世界的真实数据分布是未知的，因此通常在测试集$D_{\text{test}}$上评
估模型性能$\gamma_{\text {test }}:\left(1 /\left|D_{\text {test }}\right|\right)
\sum_{(x, y) \in D_{\text {test }}} \mathbb{I}[f(x)=y]$。若${f}$的泛化能力较强，
则其在足够充分的测试集$D_{\text{test}}$上的性能应接近其在真实数据分布$D_{gt}$上
的性能。因此，\textbf{针对泛化能力的深度学习模型测试目标}为：
\begin{itemize}
    \item[（1）] 找到测试数据$(x, y)$使得模型做出错误预测，即$(x, y) \in D \cdot f(x)
    \neq y$;
    \item[（2）] 生成测试数据集$\mathcal{D}_{\text{test}} \sim \mathcal{D}_{\text{gt}}$
    ，以揭示模型在真实数据分布上所期望的性能$\gamma_{gt}$和实际测试集上所表现的
    性能$\gamma_{\text{test}}$之间的差异；
    \item[（3）] 根据测试反馈信息，找到模型在泛化能力上的不足，进一步提升模型性能。
\end{itemize}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.7\linewidth]{intro.pdf}
    \caption{深度神经网络测试示意}
    \label{fig:ch1:intro}
\end{figure}

深度神经网络测试（见\cref{fig:ch1:intro}）是衡量和改善深度学习模型质量问题的重要
手段，已成为助力深度学习技术在安全攸关领域成功落地的新兴研究热点。如
\cref{fig:ch1:intro}所示，给定一个深度神经网络，测试度量指标用于衡量测试集对深度
神经网络的测试充分程度；测试输入生成用于生成用于测试深度神经网络的输入数据，可分
为自然样本和人工样本，通常根据不同测试度量来指标测试输入生成；测试预言是指衡量深
度神经网络在各种输入下的表现是否符合预期的标准。经过系统性测试，能够获得测试集对
深度神经网络的测试覆盖率以及成功/失效执行的测试用例，并根据测试反馈信息指导输入
数据生成，找到更多使模型做出错误决策的测试数据，辅助训练数据扩充和模型修复。

%美国白宫颁布了《维护美国在人工智能领域领导地位》、《国家人工智能研发战略》；欧
%盟致力于打造“从实验室进入市场”，发布《2021人工智能协调计划审查》；俄罗斯发布
%《2030年前国家人工智能发展战略》； 2017年7月，我国国务院印发《新一代人工智能发
%展规划》，旨在构筑我国人工智能发展的先发优势，2019年科技部印发《国家新一代人工
%智能创新发展试验区建设工作指引》，全面提升人工智能创新能力和水平。



%2019年国家新一代人工智能治理专业委员会发布《新一代人工智能治理原则——发展负责任
%的人工智能》，该文件中指出“\textbf{人工智能系统应不断提升透明性、可解释性、可靠
%性、可控性}，逐步实现可审核、可监督、可追溯、可信赖”。

% 2. 现有工作和方法的不足
近年来,越来越多的研究致力于解决深度神经网络的测试问题。加拿大阿尔伯塔大学的Lei
Ma团队深入研究了深度学习覆盖性指标~\cite{ma2018deepgauge,ma2019deepct}、测试数据
生成~\cite{xie2019coverage,xie2019deephunter}、鲁棒性
~\cite{wang2020deepsonar,sun2020stealthy,zhang2020generating}和模型修复
~\cite{yu2021deeprepair}等方面。国内南京大学的陈振宇老师团队在对话系统
~\cite{liu2021dialtest}、医疗~\cite{hou2021taumed}、机器翻译
~\cite{ji2021automated}、司法文书~\cite{guo2020taujud}、深度学习框架测试
~\cite{zhang2021duo,zhang2021predoo,luo2021graph}等领域取得了很好的研究成
果。\textbf{本项目申请人也在自动驾驶软件安全方面提出了针对神经网络模型的测试数据
集生成方法~\cite{xu2021deepsuite}}。虽然已有研究在测试度量指标构建、测试输入生成
和测试预言生成等方面已取得良好研究成果，但受传统结构覆盖测试的影响，\textbf{现有
研究主要集中于对以神经元为基本单位的神经网络架构进行结构覆盖测试}，从神经网络和
传统软件的主要区别以及深度学习模型测试的实际需求方面考虑，现有研究主要存在以下问
题：

\textbf{（1）测试指标伸缩性差，难以适用于大规模深度学习模型}

随着数据和算力的发展，深度学习模型的规模近年来呈越来越大的趋势，很多研究证明了大
规模模型对复杂问题的解决能力。然而，现有的深度学习结构覆盖测试指标大多难以适用于
大规模深度学习模型，主要体现在以下两个方面：第一，随着模型复杂度的提高，神经元和
其取值组合的数量也随之提高，以神经元为基础结构的结构覆盖率和测试多样性之间的相关
性越来越小，导致结构覆盖率对测试集质量的评估能力骤减；第二，现有结构覆盖指标的计
算复杂度与神经元的个数或训练集的规模呈线性增长关系，因次伸缩性较差，难以适用于部
署于真实世界的大规模深度学习模型。


\textbf{（2）测试结果缺乏可解释性，难以辅助开发人员修复模型}

面向深度学习模型的系统性测试，不仅要评估深度学习模型在特定测试集上的性能表现，还
需要建立测试结果与模型行为的联系，从而辅助开发人员修复提升模型。由于深度学习模型
的黑盒性质，现有的基于神经元的结构覆盖指标不能体现深度学习系统的决策逻辑，缺乏有
效语义。虽然在测试覆盖指标的引导下可以生成测试数据，暴露模型的错误行为，但与传统
软件不同的是，开发人员无法知道这些测试数据的成功或失效执行的根本原因，缺乏可解释
性的测试结果很难辅助开发人员定位模型缺陷，提升模型性能。

\textbf{（3）测试数据的标注成本过高，对测试用例集效率控制不足}

测试用例由输入数据和预期输出两部分组成。在测试一个深度学习模型时，其输入数据的样
本空间经常较大，而人工标注预期输出的成本较高，因此很难在系统部署前检测每个潜在数
据样本的预测正确性。比如图片分类任务中，输入数据是高维连续的图像数据，目前对图像
的自动标注研究尚在起步阶段，通常需要人工标注图片的类别作为测试用例的预期输出，在
执行测试用例后，根据模型的输出是否符合预期来判断测试用例的成功与否。与此同时，如
上文所述，有效评估深度学习模型的泛化能力对测试数据集的质量有较高要求，即期望测试
数据集能够尽可能模拟深度学习模型的每个状态，从而避免在系统部署后仍然存在大量意外
输入，导致模型决策错误。为了在有限成本空间内准确评估模型，需要提高测试用例集的效
率，生成规模小、检测能力强的测试用例集。


% 4. 研究方法
深度学习技术正在潜移默化地改变人们的工作和生活方式，其在自动驾驶、恶意软件检测以
及飞机碰撞避免系统等安全攸关领域部署的核心在于“质量”，而深度学习系统测试技术是保
障深度学习模型质量的必要手段，在这一背景下，\textbf{本项目针对深度神经网络测试存
在的伸缩性差、缺乏可解释性和标注成本过高的问题，研究适用于复杂神经网络、兼顾测试
成本和测试质量的可解释测试技术，解决了神经网络的黑盒复杂特性给系统性测试带来的挑
战，为深度学习模型部署在安全攸关领域提供核心技术支撑。}


\input{relatedwork.tex}