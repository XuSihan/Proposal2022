\subsection{国内外研究现状及发展动态分析}\label{relatedwork}

% 根据与本项目的相关性，本节从覆盖充分性指标、神经网络测试数据生成、深度学习框架测试以及第三方组件漏洞挖掘四个方面介绍和分析国内外研究现状。

根据与本项目的相关性，本节从覆盖充分性指标体系、测试数据集生成方法、测试数据集优选方法、深度学习框架测试及可解释性四个方面介绍和分析国内外研究现状。

%研究现状：
%1.覆盖充分性指标体系--缺点，找不到失效原因，不可解释
%2.测试数据集生成方法--本项目申请人--缺点，仅仅针对神经网络，也就是智能组件
%3.框架测试方法--缺点，忽略了其它第三方组件漏洞，可以攻击框架漏洞，给智能组件带来安全威胁，也可以直接激活智能组件的脆弱性。
%4.第三方组件漏洞挖掘--缺点，单组建非跨组件，更缺少组件对人工智能模型各阶段的影响分析。



\subsubsection{覆盖充分性指标研究}
深度学习测试中的神经元覆盖率的思想启发自传统软件测试中的白盒测试。
对于传统软件，如果遍历所有的分支语句结构就表明所有可能的输入都能够得到合理的输出。
而对于深度神经网络，由于模型本身的高纬特征和连续性导致测试样本无法遍历所有可能的输入空间。因此，测试者期望测试数据集包含尽可能更多样化的测试样例，以更好的评估模型的准确性和鲁棒性。各种神经网络结构覆盖率指标从不同角度测试评估了测试数据集的多样性和完备性，因此对深度学习白盒测试具有重要意义。 
现有的覆盖充分性指标如表\cref{tab:coverage_criteria}所示。
K.Pei等人~\citess{Pei2019DeepXplore}首次提出了深度学习系统的第一个覆盖标准。他们强调了神经元激活值对于捕捉深度神经网络(DNN) 内部状态的重要性。如果神经元的值高于预定义的阈值，则认为其被激活。神经元覆盖
Sun等人~\citess{Sun2018Testing}提出将传统的 MC/DC 覆盖标准应用于DNN，通过结构覆盖率指标的指导用梯度搜索的方法生成新的测试样例集。
率（NC）被定义为测试激活的独特神经元的覆盖率。
Ma等人~\citess{ma2018deepgauge}为神经网络模型设计了一套多粒度测试覆盖率，分为神经元粒度和区间粒度。具体来说，他们提出了 k区间覆盖率(KMNC)，将每个神经元的输出范围基于训练集的上下界平均划分为 k个部分，并计算测试数据集覆盖的比例。他们还提出了神经元边界覆盖指标（NBC）和强神经元激活覆盖指标（SNAC），它们着重考量了测试样本神经元激活值超过训练集边界的比率。此外，他们还设计了神经元相对活跃度覆盖率，它计算了曾经是最活跃的神经元之一的神经元的比率~\citess{ma2019deepct}。
Wang 等人~\citess{Wang2019DeepPath}提出了一组针对DNN模型的路径驱动的测试度量指标DeepPath,能够更好地识别对抗性样本。
Tian等人~\citess{Tian2019Testing}提出了白盒测试框架DeepInspect来自动检测基于DNN的图片分类器的混淆和偏差错误。
Du等人~\citess{Du2018DeepCruiser}提出了状态级别和转换级别两种基于抽象状态转换模型的RNN网络测试覆盖准则以及在此基础上的自动化测试框架DeepCruiser，能够根据覆盖范围反馈生成具有高覆盖率的测试用例,并有效地对基于RNN的自动语音识别系统进行缺陷检测。
Kim等人~\citess{Kim2019Guiding}基于模型在测试样本下的激活值和训练集中的激活值之间的距离，提出了一个名为惊喜充分性的测试覆盖标准SADL。
Gerasimou等人~\citess{Gerasimou2020Importance}设计了通过衡量神经元对分类结果的影响比例提出了重要性驱动覆盖标准IDC。

\begin{table}[t]
	\small
	\centering
	\caption{现有覆盖充分性指标总结}
	\label{tab:coverage_criteria}
	\begin{tabular}{c|c|c}
		\toprule
		文献来源 & 发表年份 & 覆盖充分性指标 \\
		\midrule
		DeepXplore~\citess{Pei2019DeepXplore} & 2017 & 神经元覆盖 \\
		\midrule
	    DeepCover~\citess{Sun2018Testing} & 2018 & 符号-符号覆盖、距离-符号覆盖、符号-值覆盖、距离-值覆盖 \\
		\midrule
		DeepGauge~\citess{ma2018deepgauge} & 2018 & k-多区域神经元覆盖、神经元边界覆盖、强神经元激活覆盖、Top-k神经元覆盖、Top-k 神经元模式 \\
		\midrule
	    DeepCT~\citess{ma2019deepct} & 2018 & t-way 组合稀疏覆盖、t-way 组合密集覆盖、(p,t)-完整性覆盖 \\
	    \midrule
	    DeepPath~\citess{Wang2019DeepPath} & 2019 & l-SAP 覆盖、l-OAP 覆盖、l-FSP 覆盖 \\
	    \midrule
	    DeepInspect~\citess{Tian2019Testing} & 2019 & 神经元激活概率向量距离、平均偏差等度量 \\
	    \midrule
	    DeepCruiser~\citess{Du2018DeepCruiser} & 2018 & 状态级别覆盖、转换级别覆盖 \\
	    \midrule
	    SADL~\citess{Kim2019Guiding} & 2019 & 意外覆盖 \\
	    \midrule
	    IDC~\citess{Gerasimou2020Importance} & 2019 & 重要性驱动覆盖 \\
		\bottomrule
	\end{tabular}
\end{table}



\subsubsection{测试数据集生成方法}


在对DNN系统的测试中,如何生成更加高质量、更容易暴露错误的测试数据是一个研究重点。
现有对深度学习框架测试数据生成方面的测试方法研究主要有基于模糊测试、基于变异测试、基于符号执行、基于Concolic测试以及基于对抗的测试数据生成方法，如表\cref{tab:testingDataGen}所示。

模糊测试通过将种子输入随机或者按照某种规则进行变换作为新的输入,并观察软件在这些非预期输入下是否会发生错误。Guo等人~\citess{Guo2018DLFuzz}提出了第一个差异模糊测试框架DLFuzz,用于指导DNN系统暴露异常行为。Odena等人~\citess{Odena2019TensorFuzz}将软件工程中的覆盖引导模糊测试概念引入神经网络领域,提出了TensorFuzz。Xie等人~\citess{xie2019coverage}提出了一个基于覆盖引导的自动化模糊测试框架DeepHunter，使用6种测试覆盖标准引导DNN模糊测试,实现了DNN模型在开发和部署两个阶段的缺陷检测。
Ma等人~\citess{Ma2018DeepMutation}借鉴传统软件变异测试的思想,将其应用到针对DNN系统的测试中,提出了DeepMutation，可以对测试用例集质量进行有效的定量分析,帮助开发人员提高测试数据能力。
Concolic测试技术~\cite{Majumdar2007Hybrid}是一种将程序具体执行与符号执行结合起来的软件测试技术。直接执行程序能够以更小的代价实现对特定输入的测试,而符号执行能够帮助以更少的执行次数发现错误,二者的结合能够发挥各自优势,以更高效率生成高质量的测试输入。Sun等人~\citess{Sun2018Concolic}将Concolic测试应用到DNN测试,提出了DeepConcolic，使用DeepXplore,DeepCover等诸多工作中提出的测试覆盖标准,将基于启发式逻辑的具体执行和符号执行相结合,证明了Concolic测试在深度神经网络测试上的有效性。Gopinath等人~\citess{Gopinath2018Symbolic}介绍了一种DNN轻量级符号执行的新技术DeepCheck,并将其应用于图像分类算法的测试,以解决DNN分析中的重要像素的识别以及创建1像素和2像素攻击等关键问题。


基于对抗的方法从机器学习和深度学习的角度入手,通过向原始样本添加微小扰动的方式产生对抗样本,使深度学习框架进行错误分类。
其中的基于对抗的DNN白盒测试方法指通过获得深度神经网络的内部状态,帮助生成对抗样本的一类方法。它利用了深度神经网络的内部信息,通常更容易生成高质量的对抗样本。Xiao等人~\citess{Xiao2018Spatially}提出了基于空间变换的图像对抗样本生成方法。He等人~\citess{He2018Decision}提出了一种针对区域分类的对抗样本生成方法OptMargin。
而其黑盒方法在生成对抗样本过程中只需要获得DNN网络在各种输入下对应的输出,而不需要关注其内部状态。Wicker等人提出一种特征引导的对抗性样本的鲁棒性测试方法~\citess{Wicker2018FeatureGuided},该方法借助尺度不变特征转换算法提取特征,通过双方博弈游戏的方式确定特征和操作像素点,并利用蒙特卡罗树搜索算法逐步探索博弈状态空间来生成对抗性样本。


由于深度学习模型的复杂性，已有数据集生成工作针对智能组件的覆盖性测试难以锁定真正失效原因和脆弱点，导致修复较为困难。同时目前工作缺乏对可解释性的智能组件覆盖性测试的研究，也容易受噪声和异常样本影响，导致做出错误决策，具有较大的不确定性。
另一方面，第三方深度学习组件中存在的漏洞也可能作为智能组件脆弱点的突破口，从而威胁整个智能软件的安全性，导致智能软件出现中毒攻击、模型萃取、隐私泄露等安全威胁，然而，目前工作主要集中于单组件的脆弱性及其测试数据集生成，而对多组件、第三方智能组件以及组件间的交互影响研究较少。



\begin{table}[t]
	\small
	\centering
	\caption{深度学习模型测试数据生成方法总结}
	\label{tab:testingDataGen}
	\begin{tabular}{c|c|c|c|c}
		\toprule
		方法 & 类别 & 评价方法 & 指导目标 & 实验数据集 \\
		\midrule
		DLFuzz~\citess{Guo2018DLFuzz} & 模糊测试 & 神经元覆盖率、生成效率、图片质量 & 神经元覆盖 & MNIST、ImageNet \\
		\midrule
	    TensorFuzz~\citess{Odena2019TensorFuzz} & 模糊测试 & 数值误差、预测精度 & 激活向量 & MNIST \\
	    \midrule
	    DeepHunter~\citess{xie2019coverage} & 模糊测试 & 测试精度、测试覆盖率 & 神经元覆盖、k-多区域神经元覆盖、神经元边界覆盖、强神经元激活覆盖、top-k 神经元覆盖 & MNIST、CIFAR-10、ImageNet \\
		\midrule
		DeepConcolic~\citess{Sun2018Concolic} & Concolic测试 & 测试覆盖率、对抗性样本质量 & 符号-符号覆盖、神经元边界覆盖、神经元覆盖、Lipschitz 连续性 & MNIST、CIFAR-10 \\
		\midrule
		DeepCheck~\citess{Gopinath2018Symbolic} & 符号执行 & - & 像素重要性、像素变化个数 & MNIST \\
		\midrule
		Xiao等人~\citess{Xiao2018Spatially} & 对抗样本生成 & 人类对比评价 & 像素平移距离 & MNIST、CIFAR-10、ImageNet \\
		\midrule
		OptMargin~\citess{He2018Decision} & 对抗样本生成 & 分类准确率、失真度 & 像素值差异 & MNIST、CIFAR-10 \\
		\midrule
	    Wicker等人~\citess{Wicker2018FeatureGuided} & 对抗样本生成 & 分类置信度 & 蒙特卡罗树搜索 & MNIST、CIFAR-10、Nexar、ImageNet \\
		\bottomrule
	\end{tabular}
\end{table}




\subsubsection{测试数据集优选方法}


在对深度学习模型测试的测试数据集优选方面，
Byun等人~\citess{Byun2019Input}使用从DNN模型执行的计算中得到DNN情绪量表，提出置信度、不确定性和异常性等三种情绪指标，在深度学习模型故障揭示能力、测试集选择和再训练等方面具有有效性。
Wang等人~\citess{Wang2021Prioritizing}，结合learning-to-rank方法（一种解决排序问题的监督机器学习方法）来智能地组合变异结果用于有效的测试输入优选，在此基础上提出了方法PRIMA，认为能够杀死许多变异测试模型并产生不同预测结果的测试输入数据更有可能揭示DNN模型的错误，应该优先考虑此类数据。
Hu等人~\citess{Hu2022AnEmpirical}提出了面向测试集优选的数据分布敏感指标DAT，用来减轻数据分布差异对标注数据集选择的影响，同时此指标能够更加有效地评价面向深度学习模型测试的测试数据集优选方法。
Liu等人~\citess{Liu2022DeepState}提出一种针对RNN神经网络结构的测试集优选方法DeepState，基于RNN的神经元状态选择数据，通过捕获RNN中神经元的状态变化来识别可能错误分类的测试数据集，进一步地设计了一种测试选择方法，能够从大型数据集中获得具有强大故障检测和模型改进能力的测试数据集。
Feng等人~\citess{Feng2020DeepGini}提出一种基于DNN数据统计的测试集优选方法DeepGini，将检测错误分类概率问题简化为检测集合杂质问题，从而快速识别可能被错误分类。
Gao等人~\citess{Gao2022Adaptive}提出了一种自适应的测试集优选方法ATS，可以从大量未标记的数据中选择有效子集去标注，在评估数据集的故障检测和模型改进能力方面有提升表现。
Shen等人~\citess{Shen2020MultipleBoundary}提出了多边界聚类优选方法MCP，用于将测试数据聚类到深度学习模型的多个边界区域中，指定优先级从所有边界区域中均匀地选择样本以确保每个边界重建都有足够的有用样本，以此来更加高效地实现深度学习模型的再训练过程。

类似于测试数据集生成的工作，已有测试数据集优选工作主要集中于单组件的脆弱性及其测试数据集优选，而对多组件、第三方智能组件以及组件间的交互影响研究较少。同时在选择数据的过程中也缺乏可解释性，对于神经元、参数和激活层对测试结果的影响的综合分析较少，在通过覆盖测试来定位智能组件失效原因的过程中缺乏因果分析。



\subsubsection{深度学习框架的鲁棒性测试及可解释性研究}

Zhang等人~\citess{zhang2021duo}提出了一种结合模糊测试和差分生成输入的深度学习框架测试方法Duo，用于解释和评估TensorFlow、PyTorch、MNN、MXNet等深度学习框架；也提出了一种基于模糊测试的算子级精度测试方法Predoo~\citess{zhang2021predoo}，用于估计TensorFlow中单个深度学习算子的精度误差。
Hu等人~\citess{Hu2019DeepMutationPlusPlus}提出了一种基于变异测试的DNN工具DeepMutation++，用于对包括前馈神经网络(FNN)和有状态循环神经网络(RNN)在内的DNN的质量评估，不仅可以静态分析DNN模型对整个输入的鲁棒性，还可以通过运行时分析识别顺序输入的易受攻击部分。
Xie等人~\citess{Xie2019DiffChaser}提出了一种自动黑盒测试框架DiffChaser，用于检测深度学习模型在量化、压缩前后的非目标或目标不一致性。
Du等人~\citess{Du2020Marble}提出了的方法Marble构建了一个概率模型，通过抽象来紧凑表征RNN的鲁棒性，用于对基于RNN的深度学习系统进行定量的鲁棒性分析。

Luo等人~\citess{luo2021graph}将算子级别的覆盖指标引入图论，提出了一种基于图的模糊测试方法来捕捉深度学习框架异常、提高深度学习框架质量和可解释性的方法。
Du等人~\citess{Du2019DeepStellar}~\citess{Du2019AQuantitative}提出了一个基于对抗性样本检测和覆盖引导测试生成的深度学习模型测试方法DeepStellar，基于两个轨迹相似性指标和五个覆盖充分性指标对循环神经网络（RNN）进行定量分析和可解释性研究。
Lee等人~\citess{Lee2020Effective}提出了一种对神经网络进行白盒测试的新方法Adapt，通过使神经元选择策略不断地自适应正在进行的测试状态，增强了深度神经网络的可解释性，在覆盖率和对抗性输入方面有有效表现。
Wang等人~\citess{wang2020deepsonar}提出一种识别AI合成假声音的方法DeepSonar，利用对分层神经元激活模式学习来增强深度神经网络在语音识别方面的可解释性，推测真实和AI合成的假声音之间的细微差异，同时也对操纵攻击（例如语音转换和附加现实世界噪声）的情况具有鲁棒性。


现有工作绝大部分将传统软件测试思路改进应用到深度学习智能软件测试上，主要集中于单个组件的脆弱性，而对组件间的交互影响研究较少，尤其缺乏第三方组件漏洞对智能组件影响的研究。
然而在现实情形中，智能软件大量依赖基础库和第三方依赖库，其脆弱性来源包括智能组件脆弱性、非智能组件脆弱性以及跨组件脆弱性，而智能组件、基础框架组件以及其它第三方组件之间的交互影响尚不明确，第三方开源组件数量极大，版本较多，更新频繁，组件间依赖关系复杂，挖掘可能存在漏洞的脆弱组件难度较大。























% 相关工作总结如\cref{tab:imputation}所示。
%Beaulieu-Jones等人~\citess{beaulieu2018characterizing}在电子医疗记录上对比了12中传统机器学习模型方法，



% 因为写 demo，我把参考文献放这里了，真写本子的时候，还是要放在国内外概况那边
\begin{spacing}{1.3} % 行距
	\zihao{5} \songti
	\bibliographystyle{gbt7714-nsfc}
	\bibliography{ref}
	\vspace{11bp}
\end{spacing}
