\subsection{国内外研究现状及发展动态分析}\label{relatedwork}

% 根据与本项目的相关性，本节从覆盖充分性指标、神经网络测试数据生成、深度学习框架测试以及第三方组件漏洞挖掘四个方面介绍和分析国内外研究现状。

根据与本项目的相关性，本节从覆盖充分性指标体系、测试数据集生成、测试数据集优选、
深度学习测试可解释性和知识蒸馏技术等五个方面介绍和分析国内外研究现状。

%研究现状：
%1.覆盖充分性指标体系--缺点，找不到失效原因，不可解释
%2.测试数据集生成方法--本项目申请人--缺点，仅仅针对神经网络，也就是智能组件
%3.框架测试方法--缺点，忽略了其它第三方组件漏洞，可以攻击框架漏洞，给智能组件带来安全威胁，也可以直接激活智能组件的脆弱性。
%4.第三方组件漏洞挖掘--缺点，单组建非跨组件，更缺少组件对人工智能模型各阶段的影响分析。



\subsubsection{覆盖充分性指标研究}
针对深度神经网络的结构覆盖测试启发自传统软件的白盒测试。对于传统软件，若测试集遍
历了待测软件所有的语句、分支和路径，则在一定程度上表明测试集对软件的功能进行了充
分性测试~\cite{hilton2018large}。对于深度神经网络而言，其本身的高维连续特性导致
测试集很难遍历所有可能的输入空间，为提高测试集多样性，目前有很多研究提出了关于深
度神经网络的结构覆盖指标，从不同角度测试衡量测试集对模型的覆盖充分
性。\cref{tab:coverage_criteria}总结了现有神经网络测试覆盖指标，其中$m$表示训练
集规模，$n$表示神经元个数，$l$表示\textbf{XXX}。根据覆盖思想的不同，可分为以下六
类：

\begin{table}[htp]
	\renewcommand\arraystretch{1.5}
	\small
	\centering
	\caption{现有神经网络覆盖充分性指标}
	\label{tab:coverage_criteria}
	% \begin{tabular}{p{3cm}p{5cm}p{1cm}p{1cm}p{2cm}}
	\begin{tabular}{ccccc}
		\toprule
		\textbf{序号} & \textbf{主要思想} & \textbf{覆盖指标}       & \textbf{复杂度} & \textbf{文献号}                                                  \\
		\midrule
		1             & 基于单个神经元取值  & 神经元覆盖、$k$-多区间覆盖                    & $O(n)$          & \cite{ma2018deepgauge}\cite{Pei2019DeepXplore} \\
		2             & 训练集神经元边界  & 神经元边界覆盖、强激活覆盖                    & $O(nm)$          & \cite{ma2018deepgauge}                                           \\
		3             & 与训练数据分布的距离  & 意外覆盖，平均偏差等                & $O(nm)$         & \cite{Kim2019Guiding}\cite{Tian2019Testing}            \\
		4             & 神经元激活通路覆盖    & 符号-符号覆盖、距离-符号覆盖等 & $O(nl)$ & \cite{Wang2019DeepPath}\cite{Sun2018Testing} \\
		5             & 神经元的状态转换        & 状态级别覆盖、转换级别覆盖                         & $O(n)$          & \cite{Du2018DeepCruiser}                                         \\
		6             & 神经元组合测试    & $t$-way组合稀疏覆盖、密集覆盖等 & $O(n^2)$ & \cite{ma2019deepct} \\
		\bottomrule
	\end{tabular}
\end{table}





%其中涉及到的覆盖指标主要有神经元覆盖率(NC)，$k$区间覆盖率(KMNC)，重要性驱动覆盖
%(IDC)，神经元边界覆盖率(NBC)，强神经元覆盖率(SNC)，重要神经元覆盖(INC)，意外覆
%盖(SC)，神经元激活向量距离(NAVD)，平均偏差(MD)，重要神经元通路覆盖率(INPC)，强
%激活通路覆盖率(SAPC)，符号-符号覆盖(SSC)，距离-符号覆盖(DSC)，符号-值覆盖
%(SVC)，距离-值覆盖(DVC)，状态级别覆盖(BSC)，转换级别覆盖(BTC)，$t-way$组合稀疏
%%%%覆盖($t-way$ CSC)，$t-way$组合密集覆盖($t-way$
%CDC)，$(p,t)$完整性覆盖($(p,t)$ C)等指标。

%DeepXplore~\cite{Pei2019DeepXplore}、DeepGauge~\citess{ma2018deepgauge}、IDC~\citess{Gerasimou2020Importance}
%等工作主要围绕神经元覆盖率、K区间覆盖率、重要性驱动覆盖等测试覆盖指标。

\begin{itemize}
	\item \textbf{基于单个神经元取值}，受结构覆盖思想启发，部分研究者提出度量神
	      经元被覆盖的程度来评估测试充分性。Pei等人~\cite{Pei2019DeepXplore}首次
	      提出了针对深度学习模型白盒测试指标，即神经元覆盖，将取值高于阈值的神经
	      元视为被激活，并计算被激活神经元的比例。 Ma等人~\cite{ma2018deepgauge}
	      提出了$k$-多区间覆盖指标，基于每个神经元在训练集上的取值范围，将其划分
	      为多个取值区间，并计算对神经元值区间的覆盖率。
	      %Gerasimou等人~\citess{Gerasimou2020Importance}设计了通过衡量神经元对分类结果的影响比例提出了重要性驱动覆盖标准。

	\item \textbf{基于训练集神经元的值边界}，Ma等人~\cite{ma2018deepgauge}提出神
	经元边界覆盖指标和强激活覆盖指标，计算测试集中神经元的值超过训练集的上下边界
	的比例。

	\item \textbf{基于神经元激活值分布}，Kim等人~\cite{Kim2019Guiding}提出了“意
	      外”覆盖指标，衡量模型在测试集和训练集中神经元数据分布距离。Tian等人
	      ~\cite{Tian2019Testing}提出白盒测试框架DeepInspect来检测深度神经网络中
	      的混淆和偏差错误。

	\item \textbf{基于神经元激活通路}，Wang 等人~\cite{Wang2019DeepPath}提出了一
	      组针对神经网络模型的路径驱动的测试度量指标，能够更好地识别对抗性样本。
	      Sun等人~\cite{Sun2018Testing}提出将传统的MC/DC覆盖标准应用于深度神经网
	      络，并在此基础上采用梯度搜索的方法生成新的测试集。

	\item \textbf{基于神经元状态}，Du等人~\cite{Du2018DeepCruiser}针对循环神经网
	      络提出了状态级别和转换级别两种测试覆盖指标，根据覆盖范围反馈生成具有高
	      覆盖率的测试集，并对基于循环神经网络的自动语音识别系统进行检测。

	\item \textbf{基于神经元组合分布}，Ma等人~\cite{ma2019deepct}将组合测试应用
	于神经网络，提出了$t$-way组合稀疏覆盖、$t$-way组合密集覆盖和$(p,t)$完整性覆
	盖等指标。
\end{itemize}

{\kaishu 测试覆盖指标是衡量测试集对深度学习模型测试充分性的标尺，是深度学习测试
的重要研究问题之一。现有测试覆盖指标主要聚焦于对神经网络模型的神经元结构的覆盖研
究，缺少对高层次语义表示覆盖的研究，因此缺乏可解释性。另一方面，现有指标伸缩性较
差，其计算时间和指标有效性难以应对实际大规模模型。本项目拟提出基于知识萃取的可解
释测试覆盖指标，将知识蒸馏和知识回顾应用于神经网络模型测试，从而提升测试指标的伸
缩性和可解释性。}


\subsubsection{测试数据生成方法}

为提高深度学习模型的可靠性，使用足够的测试输入对其一般行为和各种边界条件下的行为
进行充分测试是十分必要的。在对深度学习模型的测试中，如何生成更具代表性的和更容易
暴露模型错误行为的测试数据已成为深度学习测试的一个研究重点。如
\cref{tab:testingDataGen}所示，现有测试数据生成方法可分为以下三类：

\begin{table}[htp]
	\renewcommand\arraystretch{1.5}
	\small
	\centering
	\caption{深度学习模型测试数据生成方法总结}
	\label{tab:testingDataGen}
	% \begin{tabular}{cp{5cm}p{2cm}cp{2cm}}
	\begin{tabular}{cccccc}
		\toprule
		\textbf{序号} & \textbf{算法思想} & \textbf{评价方法}               & \textbf{测试数据} & \textbf{文献号}             \\
		\midrule
		1             & 模糊测试          & 测试覆盖率、效率 & 图像、文本 & \cite{Odena2019TensorFuzz}\cite{Guo2018DLFuzz}\cite{xie2019coverage} \\
		2             & 符号执行          & 测试覆盖率、像素重要性等                              & 图像、代码              & \cite{Gopinath2018Symbolic}\cite{Sun2018Concolic} \\
		3             & 对抗样本          & 准确率、失真度、人类对比评价等 & 图像 & \cite{Xiao2018Spatially}\cite{Wicker2018FeatureGuided}\cite{He2018Decision} \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{itemize}
	\item \textbf{基于模糊测试的思想}，通过随机或者特定规则将种子输入进行变换，
	生成新的测试数据，观察模型在边界条件下是否会发生错误。Guo等人
	~\cite{Guo2018DLFuzz}首次提出神经网络模糊测试框架DLFuzz，用于指导生成暴露模
	型错误行为的测试数据。Odena等人~\cite{Odena2019TensorFuzz}利用测试覆盖指标指
	导模糊测试。在此基础上，Xie等人~\cite{xie2019coverage}提出了一个自动化模糊测
	试框架DeepHunter，使用6种测试覆盖指标实现了在深度学习模型开发和部署两个阶段
	的自动化测试。

	\item \textbf{基于符号执行}，Sun等人~\cite{Sun2018Concolic}在测试覆盖指标的
	基础上提出了DeepConcolic，结合具体执行和符号分析，提高神经网络的测试覆盖
	率。Gopinath等人~\cite{Gopinath2018Symbolic}提出了一种轻量级符号执行技术并将
	其应用于图像分类算法的测试，以解决重要像素的识别以及创建1像素和2像素攻击等关
	键问题。

	\item \textbf{基于对抗样本的方法}，通过向原始样本添加微小扰动的方式产生对抗
	      样本，使深度学习模型做出错误预测。在白盒攻击方面，Xiao等人
	      ~\cite{Xiao2018Spatially}提出了基于空间变换的图像对抗样本生成方法。He
	      等人~\cite{He2018Decision}提出了一种针对区域分类的对抗样本生成方法。在
	      黑盒攻击方面，Wicker等人~\cite{Wicker2018FeatureGuided}提出一种特征引
	      导的鲁棒性测试方法，通过双方博弈游戏的方式确定特征和操作像素点，并利用
	      蒙特卡罗树搜索算法逐步探索博弈状态空间来生成对抗性样本。
\end{itemize}


{\kaishu 在深度学习模型部署前找到容易导致模型错误行为的输入数据是必要的。现有测
试数据生成方法主要分为两类：一类受传统软件测试方法启发，在输入种子数据的基础上允
许在语义大致不变的前提下对输入进行变异，以提高覆盖率为导向生成新数据；另一类基于
对抗样本，通过基于梯度等方法搜索导致模型错误预测的最小扰动，生成新测试数据。然
而，由于神经网络的黑盒特性，这两类测试数据生成方法虽然能够暴露模型错误行为，但测
试结果缺乏可解释性，测试人员很难掌握测试成功或失效的原因，因此除扩充训练集外，对
模型修复的作用较少。本项目拟提出具有可解释性的深度学习模型测试框架，从模型和测试
数据两个角度提高深度学习测试的可解释性。}













\subsubsection{测试数据选择方法}

现有对深度学习框架测试数据集优选方面的测试方法研究主要有基于变异测试、基于边界聚类以及基于神经元状态统计的测试数据优选方法，如\cref{tab:testingDataPri}所示。

\begin{itemize}

	\item \textbf{基于变异测试。}
	      Wang等人~\citess{Wang2021Prioritizing}，结合learning-to-rank方法（一种解决排序问题的监督机器学习方法）来智能地组合变异结果用于有效的测试输入优选，在此基础上提出了方法PRIMA，认为能够杀死许多变异测试模型并产生不同预测结果的测试输入数据更有可能揭示DNN模型的错误，应该优先考虑此类数据。
	      Ma等人~\citess{Ma2018DeepMutation}借鉴传统软件变异测试的思想,将其应用到针对DNN系统的测试中,提出了DeepMutation，可以对测试用例集质量进行有效的定量分析,帮助开发人员提高选择测试数据的能力。

	\item \textbf{基于神经元状态统计。}
	      Liu等人~\citess{Liu2022DeepState}提出一种针对RNN神经网络结构的测试集优选方法DeepState，基于RNN的神经元状态选择数据，通过捕获RNN中神经元的状态变化来识别可能错误分类的测试数据集，进一步地设计了一种测试选择方法，能够从大型数据集中获得具有强大故障检测和模型改进能力的测试数据集。
	      Byun等人~\citess{Byun2019Input}使用从DNN模型执行的计算中得到DNN情绪量表，提出置信度、不确定性和异常性等三种情绪指标，在深度学习模型故障揭示能力、测试集选择和再训练等方面具有有效性。
	      Gao等人~\citess{Gao2022Adaptive}提出了一种自适应的测试集优选方法ATS，可以从大量未标记的数据中选择有效子集去标注，在评估数据集的故障检测和模型改进能力方面有提升表现。

	\item \textbf{基于数据分布。}
	      Shen等人~\citess{Shen2020MultipleBoundary}提出了多边界聚类优选方法MCP，用于将测试数据聚类到深度学习模型的多个边界区域中，指定优先级从所有边界区域中均匀地选择样本以确保每个边界重建都有足够的有用样本，以此来更加高效地实现深度学习模型的再训练过程。
	      Feng等人~\citess{Feng2020DeepGini}提出一种基于DNN数据统计的测试集优选方法DeepGini，将检测错误分类概率问题简化为检测集合杂质问题，从而快速识别可能被错误分类的测试数据。
	      Hu等人~\citess{Hu2022AnEmpirical}提出了面向测试集优选的数据分布敏感指标DAT，用来减轻数据分布差异对标注数据集选择的影响，同时此指标能够更加有效地评价面向深度学习模型测试的测试数据集优选方法。

\end{itemize}

类似于测试数据集生成的工作，已有测试数据集优选工作在选择数据的过程中也缺乏可解释性，对于神经元、参数和激活层对测试结果的影响的应用较多，因果分析较少。



\begin{table}[t]
	\renewcommand\arraystretch{1.5}
	\small
	\centering
	\caption{深度学习模型测试数据集优选方法总结}
	\label{tab:testingDataPri}
	\begin{tabular}{cccc}
		\toprule
		\textbf{序号} & \textbf{算法思想}  & \textbf{测试对象} & \textbf{文献号}                                                    \\
		\midrule
		1             & 基于变异测试       & 图像分类              & \cite{Wang2021Prioritizing}\cite{Ma2018DeepMutation}                     \\
		2             & 基于神经元状态统计 & 图像分类、自然语言识别  & \cite{Liu2022DeepState}\cite{Byun2019Input}\cite{Gao2022Adaptive}              \\
		3             & 基于数据分布       & 图像分类、自然语言识别  & \cite{Shen2020MultipleBoundary}\cite{Feng2020DeepGini}\cite{Hu2022AnEmpirical} \\
		\bottomrule
	\end{tabular}
\end{table}






\subsubsection{深度学习测试可解释性}

\iffalse
	Zhang等人~\citess{zhang2021duo}提出了一种结合模糊测试和差分生成输入的深度学习框架测试方法Duo，用于解释和评估TensorFlow、PyTorch、MNN、MXNet等深度学习框架；也提出了一种基于模糊测试的算子级精度测试方法Predoo~\citess{zhang2021predoo}，用于估计TensorFlow中单个深度学习算子的精度误差。
	Hu等人~\citess{Hu2019DeepMutationPlusPlus}提出了一种基于变异测试的DNN工具DeepMutation++，用于对包括前馈神经网络(FNN)和有状态循环神经网络(RNN)在内的DNN的质量评估，不仅可以静态分析DNN模型对整个输入的鲁棒性，还可以通过运行时分析识别顺序输入的易受攻击部分。
	Xie等人~\citess{Xie2019DiffChaser}提出了一种自动黑盒测试框架DiffChaser，用于检测深度学习模型在量化、压缩前后的非目标或目标不一致性。
	Du等人~\citess{Du2020Marble}提出了的方法Marble构建了一个概率模型，通过抽象来紧凑表征RNN的鲁棒性，用于对基于RNN的深度学习系统进行定量的鲁棒性分析。

	Luo等人~\citess{luo2021graph}将算子级别的覆盖指标引入图论，提出了一种基于图的模糊测试方法来捕捉深度学习框架异常、提高深度学习框架质量和可解释性的方法。
	Du等人~\citess{Du2019DeepStellar}~\citess{Du2019AQuantitative}提出了一个基于对抗性样本检测和覆盖引导测试生成的深度学习模型测试方法DeepStellar，基于两个轨迹相似性指标和五个覆盖充分性指标对循环神经网络（RNN）进行定量分析和可解释性研究。
	Lee等人~\citess{Lee2020Effective}提出了一种对神经网络进行白盒测试的新方法Adapt，通过使神经元选择策略不断地自适应正在进行的测试状态，增强了深度神经网络的可解释性，在覆盖率和对抗性输入方面有有效表现。
	Wang等人~\citess{wang2020deepsonar}提出一种识别AI合成假声音的方法DeepSonar，利用对分层神经元激活模式学习来增强深度神经网络在语音识别方面的可解释性，推测真实和AI合成的假声音之间的细微差异，同时也对操纵攻击（例如语音转换和附加现实世界噪声）的情况具有鲁棒性。
\fi



目前的关于深度学习可解释性的研究工作主要集中于深度学习模型决策本身的可解释性，而对深度学习测试方法的可解释性研究较少。
现有深度学习测试方法大多通过各种结构覆盖率标准来衡量DNN模型的测试充分性，然而由于DNN的黑盒特性，现有的结构覆盖指标具有较低的可解释性。
Xie等人~\citess{Xie2021NPC}提出了一种新的可解释的覆盖指标，神经元路径覆盖（NFC），类似于传统的程序控制流图，该方法首先从DNN中提取决策图，决策图的路径代表DNN的决策逻辑,基于决策图的控制流和数据流，该方法提出了两种路径覆盖的变体来衡量测试用例在执行决策逻辑时的充分性，利用NFC覆盖指标对模型实际错误和对抗样本的测试都表现良好。
此外，Chen等人~\citess{Chen2020Practical}提出了PACE用于深度学习测试的优化，它选择一小组测试输入来精确估计整个测试集的准确性，从而降低标记成本。PACE在设计的过程中也体现了可解释性和确定性，它首先结合了聚类算法，将具有不同测试能力的测试输入可解释地划分为不同的组。然后利用一种较先进的基于示例的可解释算法MMD-critic来从每个组中选择最具代表性的测试输入。

现有的结构覆盖指标具有较低的可解释性，导致大多数深度学习测试工作缺乏可解释性，对于神经元、参数和激活层对测试结果的影响的综合分析较少，在通过覆盖测试来定位智能组件失效原因的过程中缺乏因果分析。
此外，现有工作绝大部分将传统软件测试思路改进应用到深度学习智能软件测试上，主要集中于单个组件的脆弱性，而对大型智能软件中各组件间的交互影响研究较少，尤其缺乏第三方深度学习组件漏洞对智能软件影响的研究分析。

%然而在现实情形中，智能软件大量依赖基础库和第三方依赖库，其脆弱性来源包括智能组件脆弱性、非智能组件脆弱性以及跨组件脆弱性，而智能组件、基础框架组件以及其它第三方组件之间的交互影响尚不明确，第三方开源组件数量极大，版本较多，更新频繁，组件间依赖关系复杂，挖掘可能存在漏洞的脆弱组件难度较大。



\subsubsection{知识蒸馏技术}

知识蒸馏~\citess{Gou2021KnowledgeDA}~\citess{Wang2021KnowledgeDA}是一种教师-学生（Teacher-Student）模型训练结构，目标是以尽可能小的代价将教师模型学到的知识迁移到简单的学生模型中。
知识蒸馏技术在深度学习模型压缩方面具有优势，同时也对深度学习模型的可解释性研究有帮助作用。

\begin{itemize}
	\item \textbf{基于知识蒸馏的模型压缩。}
	      基于知识蒸馏的模型压缩是将多个模型的知识提炼到单一模型，很多时候可以取得和单纯的模型集成学习相当甚至更优的性能表现，同时得到更加轻量化的单模型，更容易进行存储、部署和测试，目前在图像、文本、音频等多种模态数据的处理任务中均有应用。
	      在计算机视觉方面，Hou等人~\citess{Hou2020CVPR}通过传输图像样本中不同区域之间的结构关系，将教师网络学习到的场景结构知识迁移给学生执行道路标记分割任务。
	      Fu等人~\citess{Fu2020Ultrafast}提出将教师模型学习到的空间和时间知识迁移到低分辨率的轻量级时空网络中来执行视频注意预测任务，高分辨率数据上训练得到的知识在低分辨率图片处理任务上具有重要价值，同时能够降低对于计算机资源和存储的要求。
	      在自然语言处理方面，Wang等人~\citess{Wang2020StructureLevelKD}和Mukherjee等人~\citess{Mukherjee2020XtremeDistilMD}都是将若干单语言的教师模型学习到的结构知识和内部特征迁移到统一的多语言学生模型，来得到轻量级的多语言序列标注模型，而且其性能表现比原有复杂模型更优。
	      在语音识别领域，Gustavo Aguilar等人~\citess{Aguilar2020KnowledgeDF}提出将教师网络的多个Transformer层的特征知识压缩到学生的单个Transformer层中，Liu等人~\citess{Liu2019EndtoEndST}提出引入自适应层来压缩Transformer结构，在保持transformer对长序列学习问题的优越性的同时，也减轻了它过大的参数规模，便于计算和存储。

	\item \textbf{基于知识蒸馏的模型可解释性。}
	      一方面，知识蒸馏技术可以促进深度学习模型可解释性的研究。Liu等人~\citess{Liu2018ImprovingTI}通过应用知识蒸馏技术将深度神经网络提炼和表示成决策树，将已有问题转化为多输出回归问题，可以同时获得良好的性能和可解释性。
	      另一方面，知识蒸馏本身也具有一定的可解释性，从而可以帮助生成可解释的轻量级模型。
	      Cheng等人~\citess{Cheng2020ExplainingKD}通过对深度神经网络中间层的量化和分析，提出了对知识蒸馏所得学生模型性能优越的解释，认为知识蒸馏使DNN比从原始数据中学习到更多的视觉概念、也使DNN拥有易于同时学习各种视觉概念的能力，认为知识蒸馏可以产生更稳定的优化方向等。
	      此外，Phuong等人~\citess{Phuong2019TowardsUK}通过研究线性和深度线性分类器，提出了蒸馏成功的三个关键原因： 数据几何——数据分布的几何特性，特别是类分离对风险的收敛速度有直接影响；优化偏差——梯度下降优化找到对蒸馏目标的非常有利的极小值；强单调性——当训练集的大小增加时，学生分类器的预期风险总是降低。
\end{itemize}

总体来说，知识蒸馏技术在深度学习模型压缩方面具有优势，可以帮助获得性能更好且轻量级的模型，便于智能软件中各深度学习组件的测试、部署和拓展。
同时，知识蒸馏技术也对深度学习模型的可解释性研究有帮助作用，可以辅助本项目提升智能软件及其组件的可解释性和可靠性。












% 因为写 demo，我把参考文献放这里了，真写本子的时候，还是要放在国内外概况那边
\begin{spacing}{1.3} % 行距
	\zihao{5} \songti
	\bibliographystyle{gbt7714-nsfc}
	\bibliography{ref,cai_refs}
	\vspace{11bp}
\end{spacing}
