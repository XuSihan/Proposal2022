\subsection{国内外研究现状及发展动态分析}\label{relatedwork}

% 根据与本项目的相关性，本节从覆盖充分性指标、神经网络测试数据生成、深度学习框架测试以及第三方组件漏洞挖掘四个方面介绍和分析国内外研究现状。

根据与本项目的相关性，本节从覆盖充分性指标体系、测试数据集生成方法、测试数据集优选方法、深度学习测试可解释性、知识蒸馏技术等五个方面介绍和分析国内外研究现状。

%研究现状：
%1.覆盖充分性指标体系--缺点，找不到失效原因，不可解释
%2.测试数据集生成方法--本项目申请人--缺点，仅仅针对神经网络，也就是智能组件
%3.框架测试方法--缺点，忽略了其它第三方组件漏洞，可以攻击框架漏洞，给智能组件带来安全威胁，也可以直接激活智能组件的脆弱性。
%4.第三方组件漏洞挖掘--缺点，单组建非跨组件，更缺少组件对人工智能模型各阶段的影响分析。



\subsubsection{覆盖充分性指标研究}

深度学习测试中的神经元覆盖率的思想启发自传统软件测试中的白盒测试。
对于传统软件，如果遍历所有的分支语句结构就表明所有可能的输入都能够得到合理的输出。
而对于深度神经网络，由于模型本身的高纬特征和连续性导致测试样本无法遍历所有可能的输入空间。因此，测试者期望测试数据集包含尽可能更多样化的测试样例，以更好的评估模型的准确性和鲁棒性。各种神经网络结构覆盖率指标从不同角度测试评估了测试数据集的多样性和完备性，因此对深度学习白盒测试具有重要意义。
现有的覆盖充分性指标如\cref{tab:coverage_criteria}所示，
现有的覆盖指标主要基于研究神经元的激活值、激活值边界、激活值分布、激活通路以及神经元的状态或者组合分布等思想。
其中涉及到的覆盖指标主要有神经元覆盖率(NC)，$k$区间覆盖率(KMNC)，重要性驱动覆盖(IDC)，神经元边界覆盖率(NBC)，强神经元覆盖率(SNC)，重要神经元覆盖(INC)，意外覆盖(SC)，神经元激活向量距离(NAVD)，平均偏差(MD)，
重要神经元通路覆盖率(INPC)，强激活通路覆盖率(SAPC)，符号-符号覆盖(SSC)，距离-符号覆盖(DSC)，符号-值覆盖(SVC)，距离-值覆盖(DVC)，
状态级别覆盖(BSC)，转换级别覆盖(BTC)，$t-way$组合稀疏覆盖($t-way$ CSC)，$t-way$组合密集覆盖($t-way$ CDC)，$(p,t)$完整性覆盖($(p,t)$ C)等指标。

\begin{itemize}
	\item \textbf{基于单个神经元的激活值。}DeepXplore~\citess{Pei2019DeepXplore}、DeepGauge~\citess{ma2018deepgauge}、IDC~\citess{Gerasimou2020Importance}等工作主要围绕神经元覆盖率、K区间覆盖率、重要性驱动覆盖等测试覆盖指标。
	      其中，K.Pei等人~\citess{Pei2019DeepXplore}首次提出了深度学习系统的第一个覆盖标准DeepXplore，强调了神经元激活值对于捕捉深度神经网络(DNN) 内部状态的重要性，如果神经元的值高于预定义的阈值，则认为其被激活，神经元覆盖率（NC）被定义为测试激活的独特神经元的覆盖率。
	      Ma等人~\citess{ma2018deepgauge}为神经网络模型设计了一套多粒度测试覆盖率DeepGauge，分为神经元粒度和区间粒度，具体来说，他们提出了k区间覆盖率，将每个神经元的输出范围基于训练集的上下界平均划分为k个部分，并计算测试数据集覆盖的比例。
	      Gerasimou等人~\citess{Gerasimou2020Importance}设计了通过衡量神经元对分类结果的影响比例提出了重要性驱动覆盖标准。

	\item \textbf{基于神经元激活值边界。}Ma等人~\citess{ma2018deepgauge}还提出了神经元边界覆盖指标和强神经元激活覆盖指标），它们着重考量了测试样本神经元激活值超过训练集边界的比率。

	\item \textbf{基于神经元激活值分布。}DeepGauge~\citess{ma2018deepgauge}，SADL~\citess{Kim2019Guiding}，DeepInspect~\citess{Tian2019Testing}等工作主要基于神经元激活值分布来围绕重要神经元覆盖，意外覆盖，神经元激活向量距离，平均偏差等测试覆盖指标进行研究。
	      其中，Kim等人~\citess{Kim2019Guiding}基于模型在测试样本下的激活值和训练集中的激活值之间的距离，提出了一个名为惊喜充分性的测试覆盖标准SADL。
	      Tian等人~\citess{Tian2019Testing}提出了白盒测试框架DeepInspect来自动检测基于DNN的图片分类器的混淆和偏差错误。

	\item \textbf{基于神经元激活通路。}DeepGauge~\citess{ma2018deepgauge}，DeepPath~\citess{Wang2019DeepPath}，DeepCover~\citess{Sun2018Testing}等工作主要基于神经元激活通路来提出了重要神经元通路覆盖率，强激活通路覆盖率，符号-符号覆盖，距离-符号覆盖，符号-值覆盖，距离-值覆盖等指标。
	      其中，Wang 等人~\citess{Wang2019DeepPath}提出了一组针对DNN模型的路径驱动的测试度量指标DeepPath,能够更好地识别对抗性样本。
	      Sun等人~\citess{Sun2018Testing}提出将传统的MC/DC覆盖标准应用于DNN，通过结构覆盖率指标的指导用梯度搜索的方法生成新的测试样例集。

	\item \textbf{基于神经元状态。}DeepCruiser~\citess{Du2018DeepCruiser}等工作提出了状态级别覆盖，转换级别覆盖等覆盖指标。
	      Du等人~\citess{Du2018DeepCruiser}提出了状态级别和转换级别两种基于抽象状态转换模型的RNN网络测试覆盖准则以及在此基础上的自动化测试框架DeepCruiser，能够根据覆盖范围反馈生成具有高覆盖率的测试用例,并有效地对基于RNN的自动语音识别系统进行缺陷检测。

	\item \textbf{基于神经元组合分布。}Ma等人~\citess{ma2019deepct}还设计了神经元相对活跃度覆盖率，它计算了曾经是最活跃的神经元之一的神经元的比率，提出了$t-way$组合稀疏覆盖，$t-way$组合密集覆盖，$(p,t)$完整性覆盖等覆盖指标。
\end{itemize}

总体来说，现有深度学习测试方法大多通过各种结构覆盖率标准来衡量DNN模型的测试充分性，然而由于DNN的黑盒特性，现有的结构覆盖指标绝大多数都具有较低的可解释性。


\begin{table}[t]
	\small
	\centering
	\caption{现有覆盖充分性指标总结}
	\label{tab:coverage_criteria}
	% \begin{tabular}{p{3cm}p{5cm}p{1cm}p{1cm}p{2cm}}
	\begin{tabular}{cccccc}
		\toprule
		\textbf{序号} & \textbf{主要思想} & \textbf{测试覆盖指标名称}        & \textbf{复杂度} & \textbf{可解释性} & \textbf{文献号}                                                  \\
		\midrule
		1             & 单个神经元激活值  & NC, KMNC, IDC                    & $O(n)$          & 无                & \cite{ma2018deepgauge,Pei2019DeepXplore,Gerasimou2020Importance} \\
		2             & 神经元激活值边界  & NBC, SNC, INC                    & $O(n)$          & 无                & \cite{ma2018deepgauge}                                           \\
		3             & 神经元激活值分布  & INC, SC, NAVD, MD                & $O(nm)$         & 无                & \cite{ma2018deepgauge,Kim2019Guiding,Tian2019Testing}            \\
		4             & 神经元激活通路    & \makecell[c]{INPC, SAPC, SSC,                                                                                                             \\ DSC, SVC, DVC} & $O(nl)$ & 无 & \cite{ma2018deepgauge,Wang2019DeepPath,Sun2018Testing} \\
		5             & 神经元状态        & BSC, BTC                         & $O(n)$          & 无                & \cite{Du2018DeepCruiser}                                         \\
		6             & 神经元组合分布    & \makecell[c]{$t-\text{way}$ CSC,                                                                                                          \\$t\text{way}$ CDC, $(p,t)$ C} & $O(n^2)$ & 无 & \cite{ma2019deepct} \\
		\bottomrule
	\end{tabular}
\end{table}






\subsubsection{测试数据集生成方法}


在对DNN系统的测试中,如何生成更加高质量、更容易暴露错误的测试数据是一个研究重点。
现有对深度学习框架测试数据生成方面的测试方法研究主要有基于模糊测试、基于符号执行、基于Concolic测试以及基于对抗样本的测试数据生成方法，如\cref{tab:testingDataGen}所示，
其中有蒙特卡洛树搜索(MCTS)，置信度(Confidence)，分类准确率(Accuracy)、失真度(Distortion)等指标。


\begin{itemize}
	\item \textbf{基于模糊测试。}模糊测试通过将种子输入随机或者按照某种规则进行变换作为新的输入,并观察软件在这些非预期输入下是否会发生错误。Guo等人~\citess{Guo2018DLFuzz}提出了第一个差异模糊测试框架DLFuzz,用于指导DNN系统暴露异常行为。Odena等人~\citess{Odena2019TensorFuzz}将软件工程中的覆盖引导模糊测试概念引入神经网络领域,提出了TensorFuzz。Xie等人~\citess{xie2019coverage}提出了一个基于覆盖引导的自动化模糊测试框架DeepHunter，使用6种测试覆盖标准引导DNN模糊测试,实现了DNN模型在开发和部署两个阶段的缺陷检测。

	\item \textbf{基于Concolic测试。}Concolic测试技术~\cite{Majumdar2007Hybrid}是一种将程序具体执行与符号执行结合起来的软件测试技术。直接执行程序能够以更小的代价实现对特定输入的测试,而符号执行能够帮助以更少的执行次数发现错误,二者的结合能够发挥各自优势,以更高效率生成高质量的测试输入。Sun等人~\citess{Sun2018Concolic}将Concolic测试应用到DNN测试,提出了DeepConcolic，使用DeepXplore,DeepCover等诸多工作中提出的测试覆盖标准,将基于启发式逻辑的具体执行和符号执行相结合,证明了Concolic测试在深度神经网络测试上的有效性。

	\item \textbf{基于符号执行。}Gopinath等人~\citess{Gopinath2018Symbolic}介绍了一种DNN轻量级符号执行的新技术DeepCheck,并将其应用于图像分类算法的测试,以解决DNN分析中的重要像素的识别以及创建1像素和2像素攻击等关键问题。

	\item \textbf{基于对抗样本。}基于对抗的方法从机器学习和深度学习的角度入手,通过向原始样本添加微小扰动的方式产生对抗样本,使深度学习框架进行错误分类。
	      其中的基于对抗的DNN白盒测试方法指通过获得深度神经网络的内部状态,帮助生成对抗样本的一类方法。它利用了深度神经网络的内部信息,通常更容易生成高质量的对抗样本。Xiao等人~\citess{Xiao2018Spatially}提出了基于空间变换的图像对抗样本生成方法。He等人~\citess{He2018Decision}提出了一种针对区域分类的对抗样本生成方法OptMargin。
	      而其黑盒方法在生成对抗样本过程中只需要获得DNN网络在各种输入下对应的输出,而不需要关注其内部状态。Wicker等人提出一种特征引导的对抗性样本的鲁棒性测试方法~\citess{Wicker2018FeatureGuided},该方法借助尺度不变特征转换算法提取特征,通过双方博弈游戏的方式确定特征和操作像素点,并利用蒙特卡罗树搜索算法逐步探索博弈状态空间来生成对抗性样本。
\end{itemize}


总体来说，这些方法大部分启发自传统的软件测试方法，与各种面向神经网络的测试覆盖指标相结合，大部分以已有的图像分类数据集为基础进行实验研究，都有允许变异的能力。然而，由于测试覆盖指标的固有缺陷，这些包括对抗样本生成在内的的测试数据生成方法的可解释性也较低，已有数据集生成工作针对智能组件的覆盖性测试难以锁定真正失效原因和脆弱点，导致修复较为困难。同时目前工作缺乏对可解释性的智能组件覆盖性测试的研究，也容易受噪声和异常样本影响，导致做出错误决策，具有较大的不确定性。
另一方面，第三方深度学习组件中存在的漏洞也可能作为智能组件脆弱点的突破口，从而威胁整个智能软件的安全性，导致智能软件出现中毒攻击、模型萃取、隐私泄露等安全威胁，然而，目前工作主要集中于单组件的脆弱性及其测试数据集生成，而对多组件、第三方智能组件以及组件间的交互影响研究较少。







\begin{table}[t]
	\small
	\centering
	\caption{深度学习模型测试数据生成方法总结}
	\label{tab:testingDataGen}
	% \begin{tabular}{cp{5cm}p{2cm}cp{2cm}}
	\begin{tabular}{cccccc}
		\toprule
		\textbf{序号} & \textbf{算法思想} & \textbf{测试目标}               & \textbf{测试数据} & \textbf{可解释性} & \textbf{文献号}             \\
		\midrule
		1             & 模糊测试          & \makecell{NBC, NC, L2 Distance,                                                                       \\ SNC, KMNC, INC} & 图像，文本 & 无 & \cite{Odena2019TensorFuzz,Guo2018DLFuzz,xie2019coverage} \\
		2             & Concolic测试      & NC, MC/DC                       & 图像              & 无                & \cite{Sun2018Concolic}      \\
		3             & 符号执行          & 无                              & 代码              & 无                & \cite{Gopinath2018Symbolic} \\
		4             & 对抗样本          & \makecell{MCTS, Confidence,                                                                           \\Accuracy, Distortion, NC} & 图像 & 无 & \cite{Xiao2018Spatially,Wicker2018FeatureGuided,He2018Decision} \\
		\bottomrule
	\end{tabular}
\end{table}





\subsubsection{测试数据集优选方法}

现有对深度学习框架测试数据集优选方面的测试方法研究主要有基于变异测试、基于边界聚类以及基于神经元状态统计的测试数据优选方法，如\cref{tab:testingDataPri}所示。

\begin{itemize}

	\item \textbf{基于变异测试。}
	      Wang等人~\citess{Wang2021Prioritizing}，结合learning-to-rank方法（一种解决排序问题的监督机器学习方法）来智能地组合变异结果用于有效的测试输入优选，在此基础上提出了方法PRIMA，认为能够杀死许多变异测试模型并产生不同预测结果的测试输入数据更有可能揭示DNN模型的错误，应该优先考虑此类数据。
	      Ma等人~\citess{Ma2018DeepMutation}借鉴传统软件变异测试的思想,将其应用到针对DNN系统的测试中,提出了DeepMutation，可以对测试用例集质量进行有效的定量分析,帮助开发人员提高选择测试数据的能力。

	\item \textbf{基于神经元状态统计。}
	      Liu等人~\citess{Liu2022DeepState}提出一种针对RNN神经网络结构的测试集优选方法DeepState，基于RNN的神经元状态选择数据，通过捕获RNN中神经元的状态变化来识别可能错误分类的测试数据集，进一步地设计了一种测试选择方法，能够从大型数据集中获得具有强大故障检测和模型改进能力的测试数据集。
	      Byun等人~\citess{Byun2019Input}使用从DNN模型执行的计算中得到DNN情绪量表，提出置信度、不确定性和异常性等三种情绪指标，在深度学习模型故障揭示能力、测试集选择和再训练等方面具有有效性。
	      Gao等人~\citess{Gao2022Adaptive}提出了一种自适应的测试集优选方法ATS，可以从大量未标记的数据中选择有效子集去标注，在评估数据集的故障检测和模型改进能力方面有提升表现。

	\item \textbf{基于数据分布。}
	      Shen等人~\citess{Shen2020MultipleBoundary}提出了多边界聚类优选方法MCP，用于将测试数据聚类到深度学习模型的多个边界区域中，指定优先级从所有边界区域中均匀地选择样本以确保每个边界重建都有足够的有用样本，以此来更加高效地实现深度学习模型的再训练过程。
	      Feng等人~\citess{Feng2020DeepGini}提出一种基于DNN数据统计的测试集优选方法DeepGini，将检测错误分类概率问题简化为检测集合杂质问题，从而快速识别可能被错误分类的测试数据。
	      Hu等人~\citess{Hu2022AnEmpirical}提出了面向测试集优选的数据分布敏感指标DAT，用来减轻数据分布差异对标注数据集选择的影响，同时此指标能够更加有效地评价面向深度学习模型测试的测试数据集优选方法。

\end{itemize}

类似于测试数据集生成的工作，已有测试数据集优选工作在选择数据的过程中也缺乏可解释性，对于神经元、参数和激活层对测试结果的影响的应用较多，因果分析较少。



\begin{table}[t]
	\small
	\centering
	\caption{深度学习模型测试数据集优选方法总结}
	\label{tab:testingDataPri}
	\begin{tabular}{ccccc}
		\toprule
		\textbf{序号} & \textbf{算法思想}  & \textbf{测试对象}      & \textbf{可解释性} & \textbf{文献号}                                                    \\
		\midrule
		1             & 基于变异测试       & 图像分类               & 无                & \cite{Wang2021Prioritizing,Ma2018DeepMutation}                     \\
		2             & 基于神经元状态统计 & 图像分类，自然语言识别 & 无                & \cite{Liu2022DeepState,Byun2019Input,Gao2022Adaptive}              \\
		3             & 基于数据分布       & 图像分类，自然语言识别 & 无                & \cite{Shen2020MultipleBoundary,Feng2020DeepGini,Hu2022AnEmpirical} \\
		\bottomrule
	\end{tabular}
\end{table}






\subsubsection{深度学习测试可解释性}

\iffalse
	Zhang等人~\citess{zhang2021duo}提出了一种结合模糊测试和差分生成输入的深度学习框架测试方法Duo，用于解释和评估TensorFlow、PyTorch、MNN、MXNet等深度学习框架；也提出了一种基于模糊测试的算子级精度测试方法Predoo~\citess{zhang2021predoo}，用于估计TensorFlow中单个深度学习算子的精度误差。
	Hu等人~\citess{Hu2019DeepMutationPlusPlus}提出了一种基于变异测试的DNN工具DeepMutation++，用于对包括前馈神经网络(FNN)和有状态循环神经网络(RNN)在内的DNN的质量评估，不仅可以静态分析DNN模型对整个输入的鲁棒性，还可以通过运行时分析识别顺序输入的易受攻击部分。
	Xie等人~\citess{Xie2019DiffChaser}提出了一种自动黑盒测试框架DiffChaser，用于检测深度学习模型在量化、压缩前后的非目标或目标不一致性。
	Du等人~\citess{Du2020Marble}提出了的方法Marble构建了一个概率模型，通过抽象来紧凑表征RNN的鲁棒性，用于对基于RNN的深度学习系统进行定量的鲁棒性分析。

	Luo等人~\citess{luo2021graph}将算子级别的覆盖指标引入图论，提出了一种基于图的模糊测试方法来捕捉深度学习框架异常、提高深度学习框架质量和可解释性的方法。
	Du等人~\citess{Du2019DeepStellar}~\citess{Du2019AQuantitative}提出了一个基于对抗性样本检测和覆盖引导测试生成的深度学习模型测试方法DeepStellar，基于两个轨迹相似性指标和五个覆盖充分性指标对循环神经网络（RNN）进行定量分析和可解释性研究。
	Lee等人~\citess{Lee2020Effective}提出了一种对神经网络进行白盒测试的新方法Adapt，通过使神经元选择策略不断地自适应正在进行的测试状态，增强了深度神经网络的可解释性，在覆盖率和对抗性输入方面有有效表现。
	Wang等人~\citess{wang2020deepsonar}提出一种识别AI合成假声音的方法DeepSonar，利用对分层神经元激活模式学习来增强深度神经网络在语音识别方面的可解释性，推测真实和AI合成的假声音之间的细微差异，同时也对操纵攻击（例如语音转换和附加现实世界噪声）的情况具有鲁棒性。
\fi



目前的关于深度学习可解释性的研究工作主要集中于深度学习模型决策本身的可解释性，而对深度学习测试方法的可解释性研究较少。
现有深度学习测试方法大多通过各种结构覆盖率标准来衡量DNN模型的测试充分性，然而由于DNN的黑盒特性，现有的结构覆盖指标具有较低的可解释性。
Xie等人~\citess{Xie2021NPC}提出了一种新的可解释的覆盖指标，神经元路径覆盖（NFC），类似于传统的程序控制流图，该方法首先从DNN中提取决策图，决策图的路径代表DNN的决策逻辑,基于决策图的控制流和数据流，该方法提出了两种路径覆盖的变体来衡量测试用例在执行决策逻辑时的充分性，利用NFC覆盖指标对模型实际错误和对抗样本的测试都表现良好。
此外，Chen等人~\citess{Chen2020Practical}提出了PACE用于深度学习测试的优化，它选择一小组测试输入来精确估计整个测试集的准确性，从而降低标记成本。PACE在设计的过程中也体现了可解释性和确定性，它首先结合了聚类算法，将具有不同测试能力的测试输入可解释地划分为不同的组。然后利用一种较先进的基于示例的可解释算法MMD-critic来从每个组中选择最具代表性的测试输入。

现有的结构覆盖指标具有较低的可解释性，导致大多数深度学习测试工作缺乏可解释性，对于神经元、参数和激活层对测试结果的影响的综合分析较少，在通过覆盖测试来定位智能组件失效原因的过程中缺乏因果分析。
此外，现有工作绝大部分将传统软件测试思路改进应用到深度学习智能软件测试上，主要集中于单个组件的脆弱性，而对大型智能软件中各组件间的交互影响研究较少，尤其缺乏第三方深度学习组件漏洞对智能软件影响的研究分析。

%然而在现实情形中，智能软件大量依赖基础库和第三方依赖库，其脆弱性来源包括智能组件脆弱性、非智能组件脆弱性以及跨组件脆弱性，而智能组件、基础框架组件以及其它第三方组件之间的交互影响尚不明确，第三方开源组件数量极大，版本较多，更新频繁，组件间依赖关系复杂，挖掘可能存在漏洞的脆弱组件难度较大。



\subsubsection{知识蒸馏技术}

知识蒸馏~\citess{Gou2021KnowledgeDA}~\citess{Wang2021KnowledgeDA}是一种教师-学生（Teacher-Student）模型训练结构，目标是以尽可能小的代价将教师模型学到的知识迁移到简单的学生模型中。
知识蒸馏技术在深度学习模型压缩方面具有优势，同时也对深度学习模型的可解释性研究有帮助作用。

\begin{itemize}
	\item \textbf{基于知识蒸馏的模型压缩。}
	      基于知识蒸馏的模型压缩是将多个模型的知识提炼到单一模型，很多时候可以取得和单纯的模型集成学习相当甚至更优的性能表现，同时得到更加轻量化的单模型，更容易进行存储、部署和测试，目前在图像、文本、音频等多种模态数据的处理任务中均有应用。
	      在计算机视觉方面，Hou等人~\citess{Hou2020CVPR}通过传输图像样本中不同区域之间的结构关系，将教师网络学习到的场景结构知识迁移给学生执行道路标记分割任务。
	      Fu等人~\citess{Fu2020Ultrafast}提出将教师模型学习到的空间和时间知识迁移到低分辨率的轻量级时空网络中来执行视频注意预测任务，高分辨率数据上训练得到的知识在低分辨率图片处理任务上具有重要价值，同时能够降低对于计算机资源和存储的要求。
	      在自然语言处理方面，Wang等人~\citess{Wang2020StructureLevelKD}和Mukherjee等人~\citess{Mukherjee2020XtremeDistilMD}都是将若干单语言的教师模型学习到的结构知识和内部特征迁移到统一的多语言学生模型，来得到轻量级的多语言序列标注模型，而且其性能表现比原有复杂模型更优。
	      在语音识别领域，Gustavo Aguilar等人~\citess{Aguilar2020KnowledgeDF}提出将教师网络的多个Transformer层的特征知识压缩到学生的单个Transformer层中，Liu等人~\citess{Liu2019EndtoEndST}提出引入自适应层来压缩Transformer结构，在保持transformer对长序列学习问题的优越性的同时，也减轻了它过大的参数规模，便于计算和存储。

	\item \textbf{基于知识蒸馏的模型可解释性。}
	      一方面，知识蒸馏技术可以促进深度学习模型可解释性的研究。Liu等人~\citess{Liu2018ImprovingTI}通过应用知识蒸馏技术将深度神经网络提炼和表示成决策树，将已有问题转化为多输出回归问题，可以同时获得良好的性能和可解释性。
	      另一方面，知识蒸馏本身也具有一定的可解释性，从而可以帮助生成可解释的轻量级模型。
	      Cheng等人~\citess{Cheng2020ExplainingKD}通过对深度神经网络中间层的量化和分析，提出了对知识蒸馏所得学生模型性能优越的解释，认为知识蒸馏使DNN比从原始数据中学习到更多的视觉概念、也使DNN拥有易于同时学习各种视觉概念的能力，认为知识蒸馏可以产生更稳定的优化方向等。
	      此外，Phuong等人~\citess{Phuong2019TowardsUK}通过研究线性和深度线性分类器，提出了蒸馏成功的三个关键原因： 数据几何——数据分布的几何特性，特别是类分离对风险的收敛速度有直接影响；优化偏差——梯度下降优化找到对蒸馏目标的非常有利的极小值；强单调性——当训练集的大小增加时，学生分类器的预期风险总是降低。
\end{itemize}

总体来说，知识蒸馏技术在深度学习模型压缩方面具有优势，可以帮助获得性能更好且轻量级的模型，便于智能软件中各深度学习组件的测试、部署和拓展。
同时，知识蒸馏技术也对深度学习模型的可解释性研究有帮助作用，可以辅助本项目提升智能软件及其组件的可解释性和可靠性。












% 因为写 demo，我把参考文献放这里了，真写本子的时候，还是要放在国内外概况那边
\begin{spacing}{1.3} % 行距
	\zihao{5} \songti
	\bibliographystyle{gbt7714-nsfc}
	\bibliography{ref,cai_refs}
	\vspace{11bp}
\end{spacing}
